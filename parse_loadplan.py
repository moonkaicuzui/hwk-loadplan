#!/usr/bin/env python3
"""
ë¡œë“œí”Œëœ Excel íŒŒì‹± ìŠ¤í¬ë¦½íŠ¸ (v6ìš©)
Ground Truth ê¸°ì¤€ BAL ì»¬ëŸ¼ í•´ì„:
- ë‚ ì§œ = ì „ëŸ‰ ì™„ë£Œì¼ (completed)
- ìˆ«ì = ë¯¸ì™„ë£Œ ì”ëŸ‰ (pending)
"""

import pandas as pd
import json
import re
import time
from datetime import datetime
from pathlib import Path

# Factoryë³„ íŒŒì¼ ê²½ë¡œ
FACTORY_FILES = {
    'A': 'A- LOADPLAN ASSEMBLY OF RACHGIA FACTORY A  12.20.2025.xlsx',
    'B': 'B- LOADPLAN ASSEMBLY OF RACHGIA FACTORY B  12.20.2025.xlsx',
    'C': 'C- LOADPLAN ASSEMBLY OF RACHGIA FACTORY C  12.20.2025.xlsx',
    'D': 'D- LOADPLAN ASSEMBLY OF RACHGIA FACTORY D  12.20.2025.xlsx'
}

# Factory A ì»¬ëŸ¼ ë§¤í•‘ (0-indexed)
COLUMNS_A = {
    'unit': 0,
    'season': 1,
    'prod_lt': 3,
    'coop': 4,
    'crd': 5,
    'sdd_original': 6,
    'sdd_current': 7,
    'code04': 8,
    'model': 9,
    'article': 10,
    'color': 11,
    'gd': 12,
    'sales_order': 13,
    'destination': 14,
    'event': 15,
    'quantity': 17,
    'mrp_qty': 18,
    'mrp_date': 19,
    'setp': 20,
    'intertek': 25,  # AQL ê²€ì‚¬ ì—¬ë¶€
    'osc_material': 26,
    'main_material': 27,
    'outsourcing_out_bal': 37,
    'outsourcing_in_bal': 38,
    'osc_vendor': 39,
    's_cut_bal': 40,
    'pre_sew_bal': 41,
    'sew_input_bal': 42,
    'sew_prod_scan': 43,
    'sew_bal': 44,
    'outsole_vendor': 48,
    's_fit_bal': 50,
    'ass_bal': 51,
    'wh_return_fac': 53,
    'wh_in_bal': 54,
    'wh_out_bal': 55,
    'pkg_type': 56,
    'inspection': 61
}

# Factory B ì»¬ëŸ¼ ë§¤í•‘ (Aì™€ ë‹¤ë¦„)
COLUMNS_B = {
    'unit': 0,
    'season': 1,
    'prod_lt': 3,
    'coop': 4,
    'crd': 5,
    'sdd_original': 6,
    'sdd_current': 7,
    'code04': 8,
    'model': 9,
    'article': 10,
    'color': 11,
    'gd': 12,
    'sales_order': 13,
    'destination': 14,
    'event': 15,
    'quantity': 17,
    'mrp_qty': 18,
    'mrp_date': 19,
    'setp': 20,
    'intertek': 24,  # AQL ê²€ì‚¬ ì—¬ë¶€
    'osc_material': 26,
    'main_material': 27,
    'outsourcing_out_bal': 37,
    'outsourcing_in_bal': 38,
    'osc_vendor': 39,
    's_cut_bal': 40,
    'pre_sew_bal': 41,
    'sew_input_bal': 42,
    'sew_prod_scan': 43,
    'sew_bal': 44,
    'outsole_vendor': 47,
    's_fit_bal': 49,
    'ass_bal': 50,
    'wh_return_fac': 52,
    'wh_in_bal': 53,
    'wh_out_bal': 54,
    'pkg_type': 55,
    'inspection': 60
}

# Factory C ì»¬ëŸ¼ ë§¤í•‘
COLUMNS_C = {
    'unit': 0,
    'season': 1,
    'prod_lt': 3,
    'coop': 4,
    'crd': 6,
    'sdd_original': 7,
    'sdd_current': 8,
    'code04': 9,
    'model': 11,
    'article': 12,
    'color': 14,
    'gd': 15,
    'sales_order': 16,
    'destination': 17,
    'intertek': 18,  # AQL ê²€ì‚¬ ì—¬ë¶€
    'event': 19,
    'quantity': 21,
    'mrp_qty': 22,
    'mrp_date': 23,
    'setp': 24,  # PO column (ìˆ˜ì •: 29â†’24)
    'osc_material': 40,
    'main_material': 41,
    'outsourcing_out_bal': 50,
    'outsourcing_in_bal': 51,
    'osc_vendor': 52,
    's_cut_bal': 53,
    'pre_sew_bal': 54,
    'sew_input_bal': 55,
    'sew_prod_scan': 56,
    'sew_bal': 57,
    'outsole_vendor': 61,
    's_fit_bal': 64,
    'ass_bal': 65,
    'wh_return_fac': 67,
    'wh_in_bal': 68,
    'wh_out_bal': 69,
    'pkg_type': 70,
    'inspection': 75
}

# Factory D ì»¬ëŸ¼ ë§¤í•‘ (Cì™€ ë‹¤ë¦„)
COLUMNS_D = {
    'unit': 0,
    'season': 1,
    'prod_lt': 2,
    'coop': 3,
    'crd': 5,
    'sdd_original': 6,
    'sdd_current': 7,
    'code04': 8,
    'model': 10,
    'article': 11,
    'color': 13,
    'gd': 14,
    'sales_order': 15,
    'destination': 16,
    'intertek': 17,  # AQL ê²€ì‚¬ ì—¬ë¶€
    'event': 18,
    'quantity': 20,
    'mrp_qty': 21,
    'mrp_date': 22,
    'setp': 23,  # PO column (ìˆ˜ì •: 28â†’23)
    'osc_material': 39,
    'main_material': 40,
    'outsourcing_out_bal': 49,
    'outsourcing_in_bal': 50,
    'osc_vendor': 51,
    's_cut_bal': 52,
    'pre_sew_bal': 53,
    'sew_input_bal': 54,
    'sew_prod_scan': 55,
    'sew_bal': 56,
    'outsole_vendor': 60,
    's_fit_bal': 62,
    'ass_bal': 63,
    'wh_return_fac': 65,
    'wh_in_bal': 66,
    'wh_out_bal': 67,
    'pkg_type': 68,
    'inspection': 73
}


def is_date_format(value):
    """ê°’ì´ ë‚ ì§œ í˜•ì‹ì¸ì§€ í™•ì¸"""
    if pd.isna(value) or value is None:
        return False

    val_str = str(value).strip()

    # ë¹ˆ ê°’ ë˜ëŠ” íŠ¹ìˆ˜ ê°’
    if not val_str or val_str in ['00:00:00', '#N/A', 'nan', 'NaN', 'None']:
        return False

    # íŠ¹ìˆ˜ ë¬¸ìì—´ (INHOUSE, NO HAPPO ë“±)
    if any(keyword in val_str.upper() for keyword in ['INHOUSE', 'HAPPO', 'OK', 'RACH']):
        return False

    # ë‚ ì§œ íŒ¨í„´ í™•ì¸
    date_patterns = [
        r'^\d{1,2}/\d{1,2}$',           # MM/DD or M/D
        r'^\d{4}\.\d{1,2}\.\d{1,2}$',   # YYYY.MM.DD
        r'^\d{4}-\d{1,2}-\d{1,2}$',     # YYYY-MM-DD
        r'^\d{1,2}-\d{1,2}$',           # MM-DD
    ]

    for pattern in date_patterns:
        if re.match(pattern, val_str):
            return True

    # pandas Timestamp ì²´í¬
    if isinstance(value, pd.Timestamp):
        return True

    return False


def is_numeric(value):
    """ê°’ì´ ìˆ«ìì¸ì§€ í™•ì¸"""
    if pd.isna(value) or value is None:
        return False

    try:
        val_str = str(value).strip()
        if not val_str or val_str in ['00:00:00', '#N/A', 'nan', 'NaN', 'None']:
            return False

        # íŠ¹ìˆ˜ ë¬¸ìì—´ ì œì™¸
        if any(keyword in val_str.upper() for keyword in ['INHOUSE', 'HAPPO', 'OK', 'RACH', '/']):
            return False

        float(val_str)
        return True
    except (ValueError, TypeError):
        return False


def parse_date_to_string(value, default_year=2025):
    """ë‚ ì§œ ê°’ì„ YYYY-MM-DD ë¬¸ìì—´ë¡œ ë³€í™˜"""
    if pd.isna(value) or value is None:
        return None

    val_str = str(value).strip()

    if isinstance(value, pd.Timestamp):
        return value.strftime('%Y-%m-%d')

    # MM/DD í˜•ì‹
    match = re.match(r'^(\d{1,2})/(\d{1,2})$', val_str)
    if match:
        month, day = int(match.group(1)), int(match.group(2))
        year = default_year if month >= 10 else default_year + 1  # 10ì›” ì´í›„ëŠ” 2025, ê·¸ ì „ì€ 2026
        return f'{year}-{month:02d}-{day:02d}'

    # YYYY.MM.DD í˜•ì‹
    match = re.match(r'^(\d{4})\.(\d{1,2})\.(\d{1,2})$', val_str)
    if match:
        return f'{match.group(1)}-{int(match.group(2)):02d}-{int(match.group(3)):02d}'

    # YYYY-MM-DD í˜•ì‹
    match = re.match(r'^(\d{4})-(\d{1,2})-(\d{1,2})$', val_str)
    if match:
        return f'{match.group(1)}-{int(match.group(2)):02d}-{int(match.group(3)):02d}'

    return val_str


def parse_bal_column(value, quantity):
    """
    BAL ì»¬ëŸ¼ íŒŒì‹± (Ground Truth ê¸°ì¤€)
    - ë‚ ì§œ = ì „ëŸ‰ ì™„ë£Œ (completed=qty, pending=0)
    - ìˆ«ì = ë¯¸ì™„ë£Œ ì”ëŸ‰ (completed=qty-ìˆ«ì, pending=ìˆ«ì)
    """
    qty = int(quantity) if pd.notna(quantity) else 0

    # ë¹ˆ ê°’ ì²˜ë¦¬
    if pd.isna(value) or value is None:
        return {'completed': 0, 'pending': qty, 'status': 'pending', 'expected_date': None}

    val_str = str(value).strip()

    # íŠ¹ìˆ˜ ê°’ ì²˜ë¦¬
    if not val_str or val_str in ['00:00:00', '#N/A', 'nan', 'NaN', 'None']:
        return {'completed': 0, 'pending': qty, 'status': 'pending', 'expected_date': None}

    # INHOUSE = ì‚¬ë‚´ ì²˜ë¦¬ (í•´ë‹¹ ì™¸ì£¼ ê³µì • ìŠ¤í‚µ, ì™„ë£Œë¡œ ê°„ì£¼)
    if 'INHOUSE' in val_str.upper():
        return {'completed': qty, 'pending': 0, 'status': 'completed', 'expected_date': None, 'note': 'INHOUSE'}

    # ë‚ ì§œ í˜•ì‹ = ì „ëŸ‰ ì™„ë£Œ (Ground Truth)
    if is_date_format(value):
        completion_date = parse_date_to_string(value)
        return {
            'completed': qty,
            'pending': 0,
            'status': 'completed',
            'expected_date': completion_date  # ì™„ë£Œì¼
        }

    # ìˆ«ì í˜•ì‹ = ë¯¸ì™„ë£Œ ì”ëŸ‰ (Ground Truth)
    if is_numeric(value):
        try:
            remaining = int(float(val_str))
            completed = max(0, qty - remaining)

            if remaining == 0:
                status = 'completed'
            elif remaining >= qty:
                status = 'pending'
            else:
                status = 'partial'

            return {
                'completed': completed,
                'pending': remaining,
                'status': status,
                'expected_date': None
            }
        except (ValueError, TypeError):
            pass

    # ì•Œ ìˆ˜ ì—†ëŠ” í˜•ì‹
    return {'completed': 0, 'pending': qty, 'status': 'unknown', 'expected_date': None, 'raw_value': val_str}


def parse_sdd(original, current):
    """SDD ê°’ íŒŒì‹± (Current ìš°ì„ )"""
    # Current ê°’ ë¨¼ì € ì‹œë„
    for val in [current, original]:
        if pd.isna(val) or val is None:
            continue
        val_str = str(val).strip()
        if val_str and val_str not in ['00:00:00', '#N/A', 'nan']:
            if is_date_format(val):
                return parse_date_to_string(val)
            return val_str
    return None


def get_year_month(date_str):
    """ë‚ ì§œ ë¬¸ìì—´ì—ì„œ YYYY-MM ì¶”ì¶œ"""
    if not date_str:
        return None
    match = re.match(r'^(\d{4})-(\d{2})', str(date_str))
    if match:
        return f'{match.group(1)}-{match.group(2)}'
    return None


def is_header_row(row, cols):
    """í—¤ë” í–‰ì¸ì§€ í™•ì¸ (ë°˜ë³µë˜ëŠ” í—¤ë” í–‰ ìŠ¤í‚µìš©)"""
    header_keywords = ['Q.ty', 'MRP.Qty', 'Dest', 'Season', 'Model', 'Article',
                       'Color', 'Unit', 'UNIT', 'Qty', 'SDD', 'CRD', 'No.', 'NO.']

    # ì£¼ìš” ì»¬ëŸ¼ë“¤ì—ì„œ í—¤ë” í‚¤ì›Œë“œ ì²´í¬
    check_indices = [cols.get('quantity', 0), cols.get('model', 0), cols.get('destination', 0)]

    for idx in check_indices:
        if idx < len(row):
            val = str(row.iloc[idx]).strip()
            if val in header_keywords:
                return True
    return False


def is_valid_quantity(value):
    """ìˆ˜ëŸ‰ ê°’ì´ ìœ íš¨í•œ ìˆ«ìì¸ì§€ í™•ì¸"""
    if pd.isna(value) or value is None:
        return False

    val_str = str(value).strip()

    # í—¤ë” í…ìŠ¤íŠ¸ ì œì™¸
    invalid_values = ['Q.ty', 'MRP.Qty', 'Qty', 'qty', 'nan', 'NaN', 'None', '',
                      'NY', 'NO', 'N/A', '#N/A', 'TBD', '-', 'Intertek']
    if val_str in invalid_values:
        return False

    try:
        num = float(val_str)
        return num > 0
    except (ValueError, TypeError):
        return False


def parse_factory_file(factory, filepath):
    """ë‹¨ì¼ ê³µì¥ íŒŒì¼ íŒŒì‹±"""
    print(f'Parsing Factory {factory}: {filepath}')

    try:
        df = pd.read_excel(filepath, header=None, skiprows=4)  # ë°ì´í„°ëŠ” 5í–‰ë¶€í„° ì‹œì‘
    except Exception as e:
        print(f'Error reading {filepath}: {e}')
        return []

    records = []
    skipped_count = 0
    error_count = 0
    # ë°ì´í„° í’ˆì§ˆ ì¹´ìš´í„° (Agent #R03)
    quality_stats = {
        'empty_destinations': 0,
        'invalid_dates': 0,
        'auto_corrected': 0
    }

    # Factoryë³„ ì»¬ëŸ¼ ë§¤í•‘ ì„ íƒ
    if factory == 'A':
        cols = COLUMNS_A
    elif factory == 'B':
        cols = COLUMNS_B
    elif factory == 'C':
        cols = COLUMNS_C
    elif factory == 'D':
        cols = COLUMNS_D
    else:
        cols = COLUMNS_A  # ê¸°ë³¸ê°’

    for idx, row in df.iterrows():
        try:
            # í—¤ë” í–‰ ìŠ¤í‚µ
            if is_header_row(row, cols):
                skipped_count += 1
                continue

            quantity = row.iloc[cols['quantity']] if cols['quantity'] < len(row) else None

            # ìœ íš¨í•œ ìˆ˜ëŸ‰ì¸ì§€ í™•ì¸
            if not is_valid_quantity(quantity):
                continue

            qty = int(float(str(quantity).strip()))

            # ê¸°ë³¸ ì •ë³´ ì²´í¬ (model ë˜ëŠ” unitì´ ìˆì–´ì•¼ ë°ì´í„° í–‰)
            unit_val = row.iloc[cols['unit']] if cols['unit'] < len(row) else None
            model_val = row.iloc[cols['model']] if cols['model'] < len(row) else None

            unit_str = str(unit_val).strip() if pd.notna(unit_val) else ''
            model_str = str(model_val).strip() if pd.notna(model_val) else ''

            # í•©ê³„ í–‰ ìŠ¤í‚µ (ëª¨ë¸ê³¼ ìœ ë‹›ì´ ëª¨ë‘ ë¹„ì–´ìˆìœ¼ë©´ í•©ê³„/ì†Œê³„ í–‰)
            if not unit_str and not model_str:
                skipped_count += 1
                continue

            # ê¸°ë³¸ ì •ë³´
            # Destination ìë™ ìˆ˜ì • (Agent #R03: Data Quality Guardian)
            dest_raw = row.iloc[cols['destination']] if cols['destination'] < len(row) else None
            dest_str = str(dest_raw).strip() if pd.notna(dest_raw) else ''

            # ë¹ˆ destination ìë™ ìˆ˜ì •
            if not dest_str or dest_str in ['nan', 'None', '#N/A']:
                dest_str = 'Unknown'
                quality_stats['empty_destinations'] += 1
                quality_stats['auto_corrected'] += 1

            record = {
                'factory': factory,
                'unit': str(row.iloc[cols['unit']]).strip() if pd.notna(row.iloc[cols['unit']]) else '',
                'season': str(row.iloc[cols['season']]).strip() if pd.notna(row.iloc[cols['season']]) else '',
                'model': str(row.iloc[cols['model']]).strip() if pd.notna(row.iloc[cols['model']]) else '',
                'article': str(row.iloc[cols['article']]).strip() if pd.notna(row.iloc[cols['article']]) else '',
                'color': str(row.iloc[cols['color']]).strip() if pd.notna(row.iloc[cols['color']]) else '',
                'destination': dest_str,
                'quantity': qty,
                'poNumber': str(row.iloc[cols['setp']]).strip() if pd.notna(row.iloc[cols['setp']]) else '',
            }

            # CRD - ì˜ëª»ëœ ë‚ ì§œ ê²€ì¦ (Agent #R03)
            crd_val = row.iloc[cols['crd']] if cols['crd'] < len(row) else None
            if crd_val and str(crd_val).strip() == '00:00:00':
                quality_stats['invalid_dates'] += 1
                record['crd'] = ''
            else:
                record['crd'] = parse_date_to_string(crd_val) if is_date_format(crd_val) else (str(crd_val).strip() if pd.notna(crd_val) else '')
            record['crdYearMonth'] = get_year_month(record['crd']) or ''

            # SDD (Current ìš°ì„ ) - ì˜ëª»ëœ ë‚ ì§œ ê²€ì¦
            sdd_orig = row.iloc[cols['sdd_original']] if cols['sdd_original'] < len(row) else None
            sdd_curr = row.iloc[cols['sdd_current']] if cols['sdd_current'] < len(row) else None

            # '00:00:00' í˜•ì‹ í•„í„°ë§
            if sdd_curr and str(sdd_curr).strip() == '00:00:00':
                quality_stats['invalid_dates'] += 1
                sdd_curr = None
            if sdd_orig and str(sdd_orig).strip() == '00:00:00':
                quality_stats['invalid_dates'] += 1
                sdd_orig = None

            record['sddValue'] = parse_sdd(sdd_orig, sdd_curr) or ''
            record['sddYearMonth'] = get_year_month(record['sddValue']) or ''

            # Code 04 (ì§€ì—° ìŠ¹ì¸)
            code04 = row.iloc[cols['code04']] if cols['code04'] < len(row) else None
            record['code04'] = str(code04).strip() if pd.notna(code04) and str(code04).strip() not in ['nan', '-', ''] else None

            # ì•„ì›ƒì†” ë²¤ë”
            outsole_vendor = row.iloc[cols['outsole_vendor']] if cols['outsole_vendor'] < len(row) else None
            record['outsoleVendor'] = str(outsole_vendor).strip() if pd.notna(outsole_vendor) else ''

            # MRP ì •ë³´
            mrp_qty = row.iloc[cols['mrp_qty']] if cols['mrp_qty'] < len(row) else None
            record['mrpQty'] = int(float(mrp_qty)) if pd.notna(mrp_qty) and is_numeric(mrp_qty) else None

            mrp_date = row.iloc[cols['mrp_date']] if cols['mrp_date'] < len(row) else None
            record['mrpDate'] = parse_date_to_string(mrp_date) if is_date_format(mrp_date) else None

            # W.H return Fac (ë¶ˆëŸ‰ ë¦¬í„´)
            wh_return = row.iloc[cols['wh_return_fac']] if cols['wh_return_fac'] < len(row) else None
            record['whReturnFac'] = int(float(wh_return)) if pd.notna(wh_return) and is_numeric(wh_return) else 0

            # Inspection (ê²€ì‚¬ ì™„ë£Œì¼)
            inspection = row.iloc[cols['inspection']] if cols['inspection'] < len(row) else None
            record['inspection'] = parse_date_to_string(inspection) if is_date_format(inspection) else None

            # Intertek (AQL ê²€ì‚¬ ì—¬ë¶€)
            if 'intertek' in cols:
                intertek_val = row.iloc[cols['intertek']] if cols['intertek'] < len(row) else None
                intertek_str = str(intertek_val).strip().upper() if pd.notna(intertek_val) else ''
                # YES/Y/OK = AQL ê²€ì‚¬ ëŒ€ìƒ, NO/N/ë¹ˆê°’ = ë¹„ëŒ€ìƒ
                record['aql'] = intertek_str in ['YES', 'Y', 'OK', '1', 'TRUE', 'AQL']
            else:
                record['aql'] = False

            # ìƒì‚° ê³µì • ë°ì´í„° (BAL ì»¬ëŸ¼ë“¤)
            production = {}

            bal_columns = {
                's_cut': cols['s_cut_bal'],
                'pre_sew': cols['pre_sew_bal'],
                'sew_input': cols['sew_input_bal'],
                'sew_bal': cols['sew_bal'],
                's_fit': cols['s_fit_bal'],
                'ass_bal': cols['ass_bal'],
                'wh_in': cols['wh_in_bal'],
                'wh_out': cols['wh_out_bal']
            }

            for process_name, col_idx in bal_columns.items():
                if col_idx < len(row):
                    bal_value = row.iloc[col_idx]
                    production[process_name] = parse_bal_column(bal_value, qty)
                else:
                    production[process_name] = {'completed': 0, 'pending': qty, 'status': 'pending', 'expected_date': None}

            # sew_prod_scanì€ ìŠ¤ìº” ìˆ˜ëŸ‰ì¼ ë¿, BAL ì»¬ëŸ¼ì´ ì •í™•í•œ ì”ëŸ‰/ì™„ë£Œ ì •ë³´
            # sew_prod_scanìœ¼ë¡œ sew_balì„ ë®ì–´ì“°ì§€ ì•ŠìŒ

            record['production'] = production

            # ì™¸ì£¼ ì”ëŸ‰ (outsourcing_in_bal)
            osc_in_bal = row.iloc[cols['outsourcing_in_bal']] if cols['outsourcing_in_bal'] < len(row) else None
            osc_remaining = parse_bal_column(osc_in_bal, qty)
            record['oscRemaining'] = osc_remaining.get('pending', qty)

            # í¸ì˜ìš© ì”ëŸ‰ í•„ë“œë“¤ (ëŒ€ì‹œë³´ë“œ í‘œì‹œìš©)
            record['remaining'] = {
                'osc': record['oscRemaining'],  # ì™¸ì£¼ ì”ëŸ‰
                'sew': production.get('sew_bal', {}).get('pending', qty),  # ì¬ë´‰ ì”ëŸ‰
                'ass': production.get('ass_bal', {}).get('pending', qty),  # ì œí™”(ì¡°ë¦½) ì”ëŸ‰
                'whIn': production.get('wh_in', {}).get('pending', qty),  # ì°½ê³ ì…ê³  ì”ëŸ‰
                'whOut': production.get('wh_out', {}).get('pending', qty)  # ì°½ê³ ì¶œê³  ì”ëŸ‰
            }
            records.append(record)

        except Exception as e:
            error_count += 1
            if error_count <= 5:  # ì²˜ìŒ 5ê°œ ì—ëŸ¬ë§Œ ì¶œë ¥
                print(f'  Warning: Row {idx}: {e}')
            continue

    # ë°ì´í„° í’ˆì§ˆ ë¦¬í¬íŠ¸ (Agent #R03: Data Quality Guardian)
    print(f'  Factory {factory}: {len(records)} records parsed, {skipped_count} header rows skipped, {error_count} errors')
    if quality_stats['auto_corrected'] > 0 or quality_stats['invalid_dates'] > 0:
        print(f'  ğŸ“Š Data Quality Report:')
        print(f'     - Empty destinations fixed: {quality_stats["empty_destinations"]}')
        print(f'     - Invalid dates filtered: {quality_stats["invalid_dates"]}')
        print(f'     - Total auto-corrections: {quality_stats["auto_corrected"]}')

    return records


def main():
    # Performance measurement (Agent #R04)
    start_time = time.time()

    # í™˜ê²½ ë³€ìˆ˜ ë˜ëŠ” í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ ê¸°ì¤€
    base_path = Path(__file__).parent.absolute()
    all_records = []

    for factory, filename in FACTORY_FILES.items():
        filepath = base_path / filename
        if filepath.exists():
            records = parse_factory_file(factory, filepath)
            all_records.extend(records)
        else:
            print(f'File not found: {filepath}')

    print(f'\nTotal records: {len(all_records)}')

    # JSON ì €ì¥
    output_path = base_path / 'parsed_loadplan_v6.json'
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(all_records, f, ensure_ascii=False, indent=2)

    # Performance measurement
    elapsed_time = time.time() - start_time
    print(f'Saved to: {output_path}')
    print(f'âš¡ Performance: {elapsed_time:.2f}ì´ˆ (ëª©í‘œ: <30ì´ˆ)')
    if elapsed_time < 30:
        print(f'   âœ… ì„±ëŠ¥ ëª©í‘œ ë‹¬ì„±!')
    else:
        print(f'   âš ï¸ ì„±ëŠ¥ ê°œì„  í•„ìš”')

    # ìƒ˜í”Œ ì¶œë ¥
    print('\n=== Sample Records ===')
    if all_records:
        # ë‹¤ì–‘í•œ ìƒíƒœì˜ ìƒ˜í”Œ ì¶œë ¥
        samples = []
        for r in all_records[:50]:
            wh_out = r.get('production', {}).get('wh_out', {})
            if wh_out.get('status') == 'completed' and len(samples) < 2:
                samples.append(('completed', r))
            elif wh_out.get('status') == 'pending' and len(samples) < 4:
                samples.append(('pending', r))
            if len(samples) >= 4:
                break

        for label, sample in samples[:2]:
            print(f'\n--- {label.upper()} ---')
            print(json.dumps(sample, ensure_ascii=False, indent=2))

    return all_records


if __name__ == '__main__':
    main()
